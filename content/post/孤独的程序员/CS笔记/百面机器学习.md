---
title: 百面机器学习
date: 2020-03-24
draft: true
categories:
- 孤独的程序员
tags:

---



## 机器学习岗位的一些面试题

【**XGBoost，GBDT啥区别**】

* 传统GBDT以CART作为基分类器，xgboost还支持线性分类器，这个时候xgboost相当于带L1和L2正则化项的逻辑斯蒂回归（分类问题）或者线性回归（回归问题）
* 传统GBDT在优化时只用到一阶导数信息，xgboost则对代价函数进行了二阶泰勒展开，同时用到了一阶和二阶导数
* xgboost在代价函数里加入了正则项，用于控制模型的复杂度。正则项里包含了树的叶子节点个数、每个叶子节点上输出的score的L2模的平方和。从Bias-variance tradeoff角度来讲，正则项降低了模型的variance，使学习出来的模型更加简单，防止过拟合，这也是xgboost优于传统GBDT的一个特性

【**L1，L2正则原理、区别**】

* **核心：L2对大数，对outlier更敏感！**
* L2 Norm对大数的惩罚比小数大！ 而L1 Norm常常产生稀疏解
* L1正则是拉普拉斯先验，而L2正则则是高斯先验，L1对极端值更能容忍；如果正则化损失项使用L1的话，那么使学习到的参数倾向于稀疏；L2范数更多是防止过拟合，并且让优化求解变得稳定很快速
* 相同点：都用于避免过拟合
* 不同点：
  * L1可以让一部分特征的系数缩小到0，从而间接实现特征选择。所以L1适用于**特征之间有关联**的情况
  * L2让所有特征的系数都缩小，但是不会减为0，它会使优化求解稳定快速。所以**L2适用于特征之间没有关联**的情况

【**xgb中L1正则怎么用的**】

L1正则树的叶子节点个数

【**python 中 list dict set 底层怎么实现**】

* 列表：Python中的列表是由**对其它对象的引用组成的连续数组**，指向这个数组的指针及其长度被保存在一个列表头结构中
* 字典：使用伪随机探测(pseudo-random probing)的**散列表**(hash table)作为字典的底层数据结构。由于这个实现细节，只有**可哈希的**对象才能作为字典的键；Python中所有不可变的内置类型都是可哈希的。可变类型（如列表，字典和集合）就是不可哈希的，因此不能作为字典的键。
* 集合：事实上，集合被实现为**带有空值的字典**，只有键才是实际的集合元素。此外，集合还利用这种没有值的映射做了其它的优化

【**list dict有什么区别**】

* dict特点： 查找和插入的速度极快，不会随着key的增加而变慢
* list： 查找和插入的时间随着元素的增加而增加

【**过拟合判断**】

* 过拟合最直观的表现就是 **training accuracy 特别高**，但是**testing accuracy 特别低**，即两者相差特别大

* 训练之前可以使用少量数据训练一个更小的模型，如果这个模型的泛化比较好的，再去train更深更大的网络。否则直接训练一个超级大网络最后发现结果不好就不好了。

【**过拟合处理**】

* early stopping
  * 连续多次测试集准确度没有提高
* 数据集扩增（Data augmentation）：
  * 从数据源头采集更多数据
  * 复制原有数据并加上随机噪声
  * 重采样
  * 根据当前数据集估计数据分布参数，使用该分布产生更多数据等
* 正则化（Regularization）
  * 控制模型空间，降低模型的复杂度，从而避免模型区过分拟合训练数据，包括噪声与异常点
* Dropout
  * 通过修改ANN中隐藏层的神经元个数来防止ANN的过拟合


【解决哈希冲突】

* 开放定址法：当冲突发生时，使用某种探查(亦称探测)技术在散列表中形成一个探查(测)序列。沿此序列逐个单元地查找，直到找到给定 的关键字，或者碰到一个开放的地址(即该地址单元为空)为止（若要插入，在探查到开放的地址，则可将待插入的新结点存人该地址单元）。查找时探查到开放的地址则表明表中无待查的关键字，即查找失败。

* 再哈希法：同时构造多个不同的哈希函数。

* 链地址法：将所有哈希地址为i的元素构成一个称为同义词链的单链表，并将单链表的头指针存在哈希表的第i个单元中，因而查找、插入和删除主要在同义词链中进行。链地址法适用于经常进行插入和删除的情况。
* 建立公共溢出区：将哈希表分为基本表和溢出表两部分，凡是和基本表发生冲突的元素，一律填入溢出表。

【距离的计算方法】

* 闵可夫斯基距离
  * **当p=2时，是欧氏距离**
  * **当p=1时，是曼哈顿距离**
* 马氏距离
  * 应对维度之间的数据相关的情况
* 内积
  * 余弦相似度
* 汉明距离
  * **相同长度**的两字符串的编辑距离
* KL散度距离

【L1正则如何求梯度】

![](https://ws2.sinaimg.cn/large/006tKfTcly1g193gew5g7j30el05f0su.jpg)


【算法题 两个300G的大文件，求两个文件的交集】

* bitset：int的最大数是2^32 - 1 == 约43亿，用一个二进制的下标来表示一个int值，大概需要43亿个bit位，即约43亿/8 = 5.4亿Byte，即约540M的内存
* hash+分治



### Bagging 和 Boosting方法简介以及区别：

1. Bagging (bootstrap aggregating): 从原始样本集中抽取训练集。每轮从原始样本集中使用Bootstraping的方法抽取n个训练样本（在训练集中，有些样本可能被多次抽取到，而有些样本可能一次都没有被抽中）。共进行k轮抽取，得到k个训练集。（k个训练集之间是相互独立的） 每次使用一个训练集得到一个模型，k个训练集共得到k个模型。（注：这里并没有具体的分类算法或回归方法，我们可以根据具体问题采用不同的分类或回归方法，如决策树、感知器等） 对分类问题：将上步得到的k个模型采用投票的方式得到分类结果；对回归问题，计算上述模型的均值作为最后的结果。（所有模型的重要性相同）

2. Boosting: 其主要思想是将弱分类器组装成一个强分类器。在PAC（概率近似正确）学习框架下，则一定可以将弱分类器组装成一个强分类器。


##### 关于Boosting的两个核心问题：

2.1 在每一轮如何改变训练数据的权值或概率分布？

通过提高那些在前一轮被弱分类器分错样例的权值，减小前一轮分对样例的权值，来使得分类器对误分的数据有较好的效果。

2.2 通过什么方式来组合弱分类器？

通过加法模型将弱分类器进行线性组合，比如AdaBoost通过加权多数表决的方式，即增大错误率小的分类器的权值，同时减小错误率较大的分类器的权值。而提升树通过拟合残差的方式逐步减小残差，将每一步生成的模型叠加得到最终模型。

3. Bagging，Boosting二者之间的区别

1）样本选择上：

Bagging：训练集是在原始集中有放回选取的，从原始集中选出的各轮训练集之间是独立的。

Boosting：每一轮的训练集不变，只是训练集中每个样例在分类器中的权重发生变化。而权值是根据上一轮的分类结果进行调整。

2）样例权重：

Bagging：使用均匀取样，每个样例的权重相等

Boosting：根据错误率不断调整样例的权值，错误率越大则权重越大。

3）预测函数：

Bagging：所有预测函数的权重相等。

Boosting：每个弱分类器都有相应的权重，对于分类误差小的分类器会有更大的权重。

4）并行计算：

Bagging：各个预测函数可以并行生成

Boosting：各个预测函数只能顺序生成，因为后一个模型参数需要前一轮模型的结果。

4. 总结：

   这两种方法都是把若干个分类器整合为一个分类器的方法，只是整合的方式不一样，最终得到不一样的效果，将不同的分类算法套入到此类算法框架中一定程度上会提高了原单一分类器的分类效果，但是也增大了计算量。



下面是将决策树与这些算法框架进行结合所得到的新的算法：

Bagging + 决策树 = 随机森林

AdaBoost + 决策树 = 提升树

Gradient Boosting + 决策树 = GBDT


#### NLP基础

【语言模型】

* 定义：
  * 对于语言序列 ![w_1,w_2,...,w_n](https://www.zhihu.com/equation?tex=w_1%2Cw_2%2C...%2Cw_n)，语言模型就是计算该序列的概率，即 ![P(w_1, w_2, ...,w_n)](https://www.zhihu.com/equation?tex=P%28w_1%2C+w_2%2C+...%2Cw_n%29) 。
  * 从机器学习的角度来看：语言模型是对语句的**概率分布**的建模。
  * 通俗解释：判断一个语言序列是否是正常语句，即是否是**人话，**例如 ![P(I \ am \ Light)>P(Light \ I \ am)](https://www.zhihu.com/equation?tex=P%28I+%5C+am+%5C+Light%29%3EP%28Light+%5C+I+%5C+am%29) 
* 分类：
  * 统计语言模型：
    * **n-gram** 语言模型
    * 优点：
      * 采用极大似然估计，参数易训练
      * 完全包含了前 n-1 个词的全部信息
      * 可解释性强，直观易理解
    * 缺点：
      * 缺乏长期依赖，只能建模到前 n-1 个词
      * 随着 n 的增大，参数空间呈指数增长
      * 数据稀疏，难免会出现OOV(集外词)的问题
      * 单纯的基于统计频次，泛化能力差
  * 神经网络语言模型
    * 基于**前馈神经网络**的模型（Bengio）
    * 基于**循环神经网络**的模型
    * 优点：
      * 长距离依赖，具有更强的约束性
      * 避免了数据稀疏所带来的OOV问题
      * 好的词表征能够提高模型泛化能力
    * 缺点：
      * 模型训练时间长
      * 神经网络黑盒子，可解释性较差



【word embedding和word2vec】

* word embedding 是一种将词向量化的概念，来源于Bengio的论文《Neural probabilistic language models》，该模型在学习语言模型的同时，也得到了词向量。**词向量可以认为是神经网络训练语言模型的副产品**。
* word2vec是谷歌提出一种word embedding 的工具或者算法集合，采用了两种模型(CBOW与skip-gram模型)与两种方法(负采样与层次softmax方法)的组合，比较常见的组合为 skip-gram+负采样方法。
* 几个比较有名的word embedding方法包括：**word2vec** (Google), **GloVe**, **wordRank**, **FastText** (Facebook)
* 负采样与层次softmax方法：减少训练参数的优化方法

【为什么word2vec中的输出层要用哈夫曼树】

* CBOW方法中，将所有词编码成哈夫曼树，然后将CBOW得到的向量输入树，目标是顺着树得到到中心词的一条路径，然后使得该路径概率乘积最大化，更新词向量。减少训练成本
* 从隐藏层到输出的softmax层，为了避免要计算所有词的softmax概率，word2vec采样了霍夫曼树来代替从隐藏层到输出softmax层的映射

【GloVe与word2vec的区别】

* Word2vec: Predictive的模型，根据context预测中间的词汇，要么根据中间的词汇预测context，分别对应了word2vec的两种训练方式cbow和skip-gram
* GloVe: Count-based模型，本质上是对共现矩阵进行降维，在word2vec的基础上增加了全局的统计特征，可以并行化

【VAE和GAN】

 VAE 跟 GAN的目标基本是一致的——希望构建一个从隐变量 *Z* 生成目标数据 *X* 的模型，但是实现上有所不同

* VAE：https://zhuanlan.zhihu.com/p/34998569
* GAN：https://www.zhihu.com/search?type=content&q=GAN

【各种深度学习中的优化方法】

https://zhuanlan.zhihu.com/p/32626442

https://juejin.im/entry/5983115f6fb9a03c50227fd4

Adam：

* 一阶动量 + 二阶动量 做偏置校正
* 思想：梯度变化较小的方向学习步长增加，变化较大的方向学习步长减小

【 **牛顿法和梯度下降法有什么不同**】

* 牛顿法是基于当前位置的切线来确定下一次的位置
* 从收敛速度上看 ，牛顿法是二阶收敛，梯度下降是一阶收敛，前者牛顿法收敛速度更快。但牛顿法仍然是局部算法，只是在局部上看的更细致，梯度法仅考虑方向，牛顿法不但考虑了方向还兼顾了**步子的大小**，其对步长的估计使用的是二阶逼近
* 从几何上说，牛顿法就是用一个二次曲面去拟合当前所处位置的局部曲面，而梯度下降法是用一个平面去拟合当前的局部曲面，通常情况下，二次曲面的拟合会比平面更好，所以牛顿法选择的下降路径会更符合真实的最优下降路径。
* 牛顿法
  * 优点：二阶收敛，收敛速度快；
  * 缺点：是一种迭代算法，每一步都需要求解目标函数的Hessian矩阵的逆矩阵，计算比较复杂
* 拟牛顿法：本质思想是改善牛顿法每次需要求解复杂的Hessian矩阵的逆矩阵的缺陷，它使用正定矩阵来近似Hessian矩阵的逆，从而简化了运算的复杂度


【**交叉验证的目的**】

1. 交叉验证用于评估模型的预测性能，尤其是训练好的模型在新数据上的表现，可以在一定程度上减小过拟合。
2. 还可以从有限的数据中获取尽可能多的有效信息

【**如何进行特征选择**】

* 可以减少特征数量、降维，使模型泛化能力更强，减少过拟合

* 常见的特征选择方式：
  * 去除方差较小的特征
  * 正则化：L1正则化能够生成稀疏的模型。L2正则化的表现更加稳定，由于有用的特征往往对应系数非零
  * 随机森林：对于分类问题，通常采用基尼不纯度或者信息增益，对于回归问题，通常采用的是方差或者最小二乘拟合
* 注意：PCA和LDA是特征降维的方法

【**ReLU的优缺点**】

* 优点：
  * 收敛速度快
  * 会使一部分神经元的输出为0，这样就造成了网络的稀疏性，并且减少了参数的相互依存关系，缓解了过拟合问题的发生

* 缺点：
  * 如果有一个特别大的导数经过神经单元使得输入变得小于0，这样会使得这个单元永远得不到参数更新，因为输入小于0时导数也是0. 这就形成了很多dead cell

* 注意：sigmoid函数反向传播时，很容易就会出现梯度消失的情况，且计算量大

【**衡量分类器的好坏**】
* 精度precision = TP/(TP+FP) = TP / ～P （～p为预测为真的数量）
* 召回率 recall = TP/(TP+FN) = TP/ P
* F1值： 2/F1 = 1/recall + 1/precision
* ROC曲线：ROC空间是一个以伪阳性率（FPR，false positive rate）为X轴，真阳性率（TPR, true positive rate）为Y轴的二维坐标系所代表的平面。其中真阳率TPR = TP / P = recall， 伪阳率FPR = FP / N

【**AUC物理含义**】
AUC是指 随机给定一个正样本和一个负样本，分类器输出该正样本为正的那个概率值 比 分类器输出该负样本为正的那个概率值 要大的可能性

【**如何解决梯度消失和梯度膨胀**】
* 梯度消失：
  * 采用ReLU激活函数
  * Batch Normalization
* 梯度膨胀
  * Batch Normalization

【**SVD和PCA**】
* PCA的理念是使得数据投影后的方差最大，找到这样一个投影向量，满足方差最大的条件即可。而经过了去除均值的操作之后，就可以用SVD分解来求解这样一个投影向量，选择特征值最大的方向。
* PCA的本质是对于一个以矩阵为参数的分布进行似然估计，而SVD是矩阵近似的有效手段。

【**梯度下降调优**】
1. **算法迭代步长$\alpha$选择。**
   在算法参数初始化时，有时根据经验将步长 初始化为1。实际取值取决于数据样本。可以从大到小，多取一些值，分别运行算法看迭代效果，如果损失函数在变小，则取值有效。如果取值无效，说明要增大步长。但步长太大，有时会导致迭代速度过快，错过最优解。步长太小，迭代速度慢，算法运行时间长。
2. **参数的初始值选择。**
   初始值不同，获得的最小值也有可能不同，梯度下降有可能得到的是局部最小值。如果损失函数是凸函数，则一定是最优解。由于有局部最优解的风险，需要多次用不同初始值运行算法，关键损失函数的最小值，选择损失函数最小化的初值。
3. **标准化处理。**
   由于样本不同，特征取值范围也不同，导致迭代速度慢。为了减少特征取值的影响，可对特征数据标准化，使新期望为0，新方差为1，可节省算法运行时间。

【**随机 / 批量梯度下降法的区别**】

随机梯度下降法、批量梯度下降法相对来说都比较极端，简单对比如下：
批量梯度下降：
a）采用所有数据来梯度下降。
b) 批量梯度下降法在样本量很大的时候，训练速度慢。

随机梯度下降：
a) 随机梯度下降用一个样本来梯度下降。
b) 训练速度很快。
c) 随机梯度下降法仅仅用一个样本决定梯度方向，导致解有可能不是最优。
d) 收敛速度来说，随机梯度下降法一次迭代一个样本，导致迭代方向变化很大，不能很快的收敛到局部最优解。

小批量梯度下降结合了以上两种方法的优点：每次随机抽取一个小批量子样本进行训练下降梯度

|       GD       |    BGD     |   SGD    | Mini-batch GD |   Online GD    |
| :------------: | :--------: | :------: | :-----------: | :------------: |
|     训练集     |    固定    |   固定   |     固定      |    实时更新    |
| 单次迭代样本数 | 整个训练集 | 单个样本 | 训练集的子集  | 根据具体算法定 |
|   算法复杂度   |     高     |    低    |     一般      |       低       |
|     时效性     |     低     |   一般   |     一般      |       高       |
|     收敛性     |    稳定    |  不稳定  |    较稳定     |     不稳定     |

Online GD在互联网领域用的较多，比如搜索广告的点击率(CTR)预估模型，网民的点击行为会随着时间改变。用普通的BGD算法（每天更新一次）一方面耗时较长（需要对所有历史数据重新训练）；另一方面，无法及时反馈用户的点击行为迁移。而Online GD算法可以实时的依据网民的点击行为进行迁移。

【**LDA思想以及和PCA的区别**】

LDA分类思想简单总结如下：

1. 多维空间中，数据处理分类问题较为复杂，LDA算法将多维空间中的数据投影到一条直线上，将d维数据转化成1维数据进行处理。
2. 对于训练数据，设法将多维数据投影到一条直线上，同类数据的投影点尽可能接近，异类数据点尽可能远离。
3. 对数据进行分类时，将其投影到同样的这条直线上，再根据投影点的位置来确定样本的类别。
   如果用一句话概括LDA思想，即“投影后类内方差最小，类间方差最大”。

| 异同点 | LDA                                                          | PCA                              |
| :----: | :----------------------------------------------------------- | :------------------------------- |
| 相同点 | 1. 两者均可以对数据进行降维；2. 两者在降维时均使用了矩阵特征分解的思想；3. **两者都假设数据符合高斯分布**； |                                  |
| 不同点 | 有监督的降维方法                                             | 无监督的降维方法                 |
|        | **降维最多降到k-1维(k为类别数)**                             | **降维多少没有限制**             |
|        | 可以用于降维，还可以用于分类                                 | 只用于降维                       |
|        | 选择分类性能最好的投影方向                                   | 选择样本点投影具有最大方差的方向 |
|        | 更明确，更能反映样本间差异                                   | 目的较为模糊                     |

【PCA】

1. PCA就是将高维的数据通过线性变换投影到低维空间上去。
2. 投影思想：找出最能够代表原始数据的投影方法。被PCA降掉的那些维度只能是那些噪声或是冗余的数据。
3. 去冗余：去除可以被其他向量代表的线性相关向量，这部分信息量是多余的。
4. 去噪声，去除较小特征值对应的特征向量，特征值的大小反映了变换后在特征向量方向上变换的幅度，幅度越大，说明这个方向上的元素差异也越大，要保留。
5. 对角化矩阵，寻找极大线性无关组，保留较大的特征值，去除较小特征值，组成一个投影矩阵，对原始样本矩阵进行投影，得到降维后的新样本矩阵。
6. 完成PCA的关键是——协方差矩阵。
   协方差矩阵，能同时表现不同维度间的相关性以及各个维度上的方差。
   协方差矩阵度量的是维度与维度之间的关系，而非样本与样本之间。
7. 之所以对角化，因为对角化之后非对角上的元素都是0，达到去噪声的目的。对角化后的协方差矩阵，对角线上较小的新方差对应的就是那些该去掉的维度。所以我们只取那些含有较大能量(特征值)的维度，其余的就舍掉，即去冗余。

两种等价的评价指标：

* 最小投影距离（和超平面距离足够近）
* 最大投影方差（投影后样本尽可能分开）

【**模型评估**】

训练误差大，测试误差小 → Bias大

训练误差小，测试误差大→ Variance大 → 降VC维

训练误差大，测试误差大→ 升VC维

![](https://ws4.sinaimg.cn/large/006tKfTcly1g1iar28j46j30ev0a43yt.jpg)

![](https://ws4.sinaimg.cn/large/006tKfTcly1g1iarv9vkdj30ea0a4aac.jpg)

【**过拟合和欠拟合**】

**如何解决欠拟合：**

1. **添加其他特征项**。组合、泛化、相关性、上下文特征、平台特征等特征是特征添加的重要手段，有时候特征项不够会导致模型欠拟合。
2. 添加多项式特征。例如将线性模型添加二次项或三次项使模型泛化能力更强。例如，FM模型、FFM模型，其实就是线性模型，增加了二阶多项式，保证了模型一定的拟合程度。
3. **增加模型的复杂程度**
4. **减小正则化系数**

**如何解决过拟合：**

1. 重新清洗数据，数据不纯会导致过拟合，此类情况需要重新清洗数据
2. 增加训练样本数量
3. **降低模型复杂程度**
4. **增大正则项系数** 
5. **采用dropout方法**
6. **early stopping** 
7. 减少迭代次数
8. 增大学习率 
9. 添加噪声数据
10. 树结构中，可以对树进行剪枝

【**ROC和AUC**】

<https://blog.csdn.net/zdy0_2004/article/details/44948511>

* AUC用于衡量“二分类问题”机器学习算法性能（泛化能力），表示正例排在负例前面的概率，能很好描述模型整体性能的高低

* 以假正率为纵坐标、真正率为横坐标绘制成曲线，曲线下面积越大，诊断准确性越高
* ROC曲线越接近左上角，该分类器的性能越好
* **首先AUC值是一个概率值，当你随机挑选一个正样本以及负样本，当前的分类算法根据计算得到的Score值将这个正样本排在负样本前面的概率就是AUC值，AUC值越大，当前分类算法越有可能将正样本排在负样本前面，从而能够更好地分类。**
* 为何使用ROC和AUC：
  * 因为ROC曲线有个很好的特性：**当测试集中的正负样本的分布变换的时候（正负样本不平衡），ROC曲线能够保持不变**。在实际的数据集中经常会出现样本类不平衡，即正负样本比例差距较大，而且测试数据中的正负样本也可能随着时间变化。

【**类别不平衡解决方法**】

* 扩大数据集
* 对大类数据欠采样
* 对小类数据过采样
* 使用新评价指标
* 选择新算法

【**决策树评价**】

决策树算法的优点：  

1、理解解释简单 

2、要求的数据集不大。

3、时间复杂度较小

4、处理数字和数据的类别

5、能够处理多输出的问题

6、对缺失值不敏感。

7、可以处理不相关特征数据。

8、效率高，决策树只需要一次构建，反复使用，每一次预测的最大计算次数不超过决策树的深度。

决策树算法的缺点： 

1、对连续性的字段比较难预测

2、容易出现过拟合

3、信息缺失时处理起来比较困难，忽略了数据集中属性之间的相关性

4、在处理特征关联性比较强的数据时表现得不是太好

5、信息增益的结果偏向于那些具有更多数值的特征

【**GBDT和随机森林的区别**】

* GBDT和随机森林的相同点：
  1、都是由多棵树组成
  2、最终的结果都是由多棵树一起决定

* GBDT和随机森林的不同点：
  1、组成随机森林的树**可以是分类树，也可以是回归树**；而GBDT只由回归树组成
  2、组成随机森林的树可以**并行生成**；而GBDT只能是**串行生成**
  3、对于最终的输出结果而言，随机森林采用**多数投票**等；而GBDT则是将所有结果累加起来，或者**加权累加**起来
  4、随机森林对**异常值不敏感**，GBDT对**异常值非常敏感**
  5、随机森林对训练集**一视同仁**，GBDT是**基于权值**的弱分类器的集成
  6、随机森林是通过**减少模型方差**提高性能，GBDT是通过**减少模型偏差**提高性能

【**维数灾难**】

问题：

* 特征数量越多，训练样本就会越稀疏，分类器的参数估计就会越不准确，更加容易出现**过拟合问题**
* 特征太多，**难以训练**

解决：**PCA、LDA、奇异值分解**

【**聚类和降维的区别**】

* 聚类针对的是数据点，而降维则是对于数据的特征
* 聚类中常用的有K-means、层次聚类、基于密度的聚类等；降维中常用的则PCA、Isomap、LLE等

【**SVM的只要特点和缺点**】

特点：

1. 利用**内积核函数**代替向高维空间的非线性映射
2. 对特征空间划分的**最优超平面**是SVM的目标,**最大化分类边际**的思想是SVM方法的核心
3. 在SVM分类决策中起**决定作用的是支持向量**
4. SVM是一种有坚实理论基础的新颖的小样本学习方法。它基本上不涉及概率测度及大数定律等,因此不同于现有的统计方法。从本质上看,它避开了从归纳到演绎的传统过程,实现了高效的从训练样本到预报样本的“转导推理”,大大简化了通常的分类和回归等问题
5. SVM 的最终决策函数只由少数的支持向量所确定,计算的复杂性取决于支持向量的数目,而不是样本空间的维数,这在某种意义上**避免了“维数灾难”**。
6. 少数支持向量决定了最终结果,这不但可以帮助我们抓住关键样本、“剔除”大量冗余样本,而且注定了该方法不但算法简单,而且**具有较好的“鲁棒”**性。这种“鲁棒”性主要体现在:
   ①增、删非支持向量样本对模型没有影响;
   ②支持向量样本集具有一定的鲁棒性;
   ③有些成功的应用中,SVM 方法对核的选取不敏感

不足：

1. SVM算法对**大规模训练样本难以实施**：由于SVM是借助二次规划来求解支持向量，而求解二次规划将涉及m阶矩阵的计算（m为样本的个数），当m数目很大时该矩阵的存储和计算将耗费大量的机器内存 和运算时间。针对以上问题的主要改进有有J.Platt的SMO算法、T.Joachims的SVM、C.J.C.Burges等的PCGC、张学工的 CSVM以及O.L.Mangasarian等的SOR算法
2. 用SVM解决**多分类问题存在困难**：经典的支持向量机算法只给出了二类分类的算法，而在数据挖掘的实际应用中，一般要解决多类的分类问题。可以通过多个二类支持向量机的组合来解决。主要有一对多组合模式、一对一组合模式和SVM决策树；再就是通过构造多个分类器的组合来解决。主要原理是克服SVM固有的缺点，结合其他算法的优势，解决多类问题的分类精度。如：与粗集理论结合，形成一种优势互补的多类问题的组合分类器

【为什么深度网络难以训练】

* 梯度消失
* 梯度爆炸
* 权重矩阵的退化导致模型的有效自由度减少

![](https://ws2.sinaimg.cn/large/006tKfTcly1g1ijl93zyyj30u01904ce.jpg)



【**Batch Normalization和Group Normalization**】

BN：在神经网络中间层也进行归一化处理，使训练效果更好的方法；

在CNN中，BN应作用在非线性映射前；在神经网络训练时遇到收敛速度很慢，或梯度爆炸等无法训练的状况时可以尝试BN来解决。减少梯度消失，加快收敛速度，提高训练精度

GN：GN 将通道分成组，并在每组内计算归一化的均值和方差

【**dropout的缺点**】

代价函数J不再被明确定义，每次迭代，都会随机移除一些节点，难以确保代价函数单调递减

【**covariate shift**】

指源空间和目标空间的**条件概率（能指示的样本标记不变）**是一致的，但是其**边缘概率（神经网络各层分布不一样）**不同

对于神经网络的各层输出，由于它们经过了层内操作作用，其分布显然与各层对应的输入信号分布不同，而且差异会随着网络深度增大而增大，可是它们所能“指示”的样本标记（label）仍然是不变的

导致的问题：每个神经元的输入数据不再是“独立同分布”

* 上层参数需要不断适应新的输入数据分布，降低学习速度
* 下层输入的变化可能趋向于变大或者变小，导致上层落入饱和区，使得学习过早停止
* 每层的更新都会影响到其它层，因此每层的参数更新策略需要尽可能的谨慎。

【CNN提高泛化能力】

* 使用正则化技术
* 增加神经网络层数
* 使用恰当的代价函数
* 使用权重初始化技术
* 人为增广训练集
* 使用dropout技术 