<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>从seq2seq到Transformer | Shuryne</title>

<meta name="keywords" content="计算机, NLP, Transformer" />
<meta name="description" content="关于Seq2Seq和Transformer">
<meta name="author" content="Shuryne">
<link rel="canonical" href="https://Shuryne.github.io/posts/%E4%BB%8Eseq2seq%E5%88%B0transformer/" />
<link href="/assets/css/stylesheet.min.599b0e9ad02d274d3cb655359f597ea4ffb4913107f886d7b6869ff79a84a726.css" integrity="sha256-WZsOmtAtJ008tlU1n1l&#43;pP&#43;0kTEH&#43;IbXtoaf95qEpyY=" rel="preload stylesheet"
    as="style">

<link rel="icon" href="https://Shuryne.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://Shuryne.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://Shuryne.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://Shuryne.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://Shuryne.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<meta name="generator" content="Hugo 0.81.0" />



<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'G-B99LVDK48T', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>
<meta property="og:title" content="从seq2seq到Transformer" />
<meta property="og:description" content="关于Seq2Seq和Transformer" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://Shuryne.github.io/posts/%E4%BB%8Eseq2seq%E5%88%B0transformer/" />
<meta property="og:image" content="https://Shuryne.github.io/papermod-cover.png"/>
<meta property="article:published_time" content="2018-11-12T00:00:00+00:00" />
<meta property="article:modified_time" content="2021-03-20T00:00:00+00:00" />

<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://Shuryne.github.io/papermod-cover.png"/>

<meta name="twitter:title" content="从seq2seq到Transformer"/>
<meta name="twitter:description" content="关于Seq2Seq和Transformer"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Posts",
      "item": "https://Shuryne.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "从seq2seq到Transformer",
      "item": "https://Shuryne.github.io/posts/%E4%BB%8Eseq2seq%E5%88%B0transformer/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "从seq2seq到Transformer",
  "name": "从seq2seq到Transformer",
  "description": "关于Seq2Seq和Transformer\n",
  "keywords": [
    "计算机", "NLP", "Transformer"
  ],
  "articleBody": "关于Seq2Seq和Transformer\n1. Sequence to Sequence Learning with Neural Networks   encoder以及decoder都采用LSTM模型\n  模型很简单，就是最普通的多层LSTM\n  实现的不同之处：\n 用两种不同的LSTM，一种处理输入序列，一种处理输出序列；以可忽略的计算成本增加参数数量，同时在多个语言对上训练LSTM； 更深的LSTM会比浅的效果更好，故论文模型选择了四层； 将输入的序列翻转之后作为输入效果提升；    decoder应用了beam search来提升效果（每次生成词是取使得整个概率最高的前k个词作为候选）；beam size越大，效果越好，同时计算代价增大；\n  关于倒序输入效果提升：rnn是有偏模型，顺序越靠后的单词在最终占据的信息量越大，正序时最后一个词对应的state作为decoder的输入来预测第一个词，在alignment上来看显然这两个词并不是对齐的；倒序的话，first word成了last word，在last state中占据了主导，来预测decoder的第一个词，从某种意义上说实现了alignment，故效果提升；\n  decoder本质上是一个rnn语言模型，不同的是在生成词的时候依赖于encoder的最后一个hidden state：\n  参考资料：\n Sequence to Sequence Learning with Neural Networks https://zhuanlan.zhihu.com/p/26985192     2. Convolutional Sequence to Sequence Learning   Seq2Seq 先把语句转换为一组词向量，通过对词向量的剪辑，提炼出语义向量。但对于如何剪辑有争议。有人提议使用LSTM等循环模型（RNN），来实现语义剪辑。RNN 模型的剪辑手段是：记忆门、遗忘门、和输出门。\n  RNN 模型的突出优势，是很好地解决了长距离依赖的难题；\n  作者使用CNN取代RNN循环模型，训练速度提高9倍，精度超越RNN；\n  为什么更快？\n 卷积并行处理，而循环只能顺序处理，多个机器同时并行训练卷积模型，速度比串行训练循环模型快很多； 可用GPU芯片来加速卷积模型的训练，而暂时还没有硬件能够加速RNN的训练；    为什么更准？\n CNN的层层抽象，与RNN的三重门，其实异曲同工。虽手段不同，但目的都是忽略次要内容，传承重要内容。所以在精度方面二者差距不大； 但是层级结构与循环网络链结构相比，提供了一种较短的路径来捕获词之间远程的依赖关系，因此也可以更好地捕捉更复杂的关系； Facebook translate 与Google translate的精度差异，应该是由于attention的改进引起的；  Google Translate的解码器使用单层LSTM模型，故attention也是单层的；Facebook的解码器使用CNN模型，是多层的，attention 是多跳的（multi-hop）；越是底层的attention越聚焦，细节越丰富；越是高层的attention，视野越开阔，抽象程度越高，越能抓住文章主旨； Google Translate使用的attention，依赖于编码器生成的语义向量，而不依赖于输入的原生态的词向量。而Facebook的attention，对语义向量和原生态词向量兼收并取；语义向量负责把握主旨，保证解码器的输出不偏题；原生态词向量关注措辞，保障解码器的输出用词得当；      将来attention的机制，还得融入规则。论文里只理解字面意思的attention的计算方式，无法理解“画外音”、“引经据典”、“含沙射影”的联想型语句。要正确理解“引经据典”和“含沙射影”，将来attention机制，还得融入知识图谱（张俊的猜想）；\n  模型结构：encoder-decoder +attention模块\n encoder 和 decoder采用了相同的卷积结构 非线性部分采用门控结构GLM； attention采用多跳注意multi-hop attention，即在decoder的每一个卷积层都会进行attention操作，并将结果输入到下一层；    参考资料\n Convolutional Sequence to Sequence Learning https://zhuanlan.zhihu.com/p/26918935 https://zhuanlan.zhihu.com/p/27464080     3. Attention Is All You Need   优点：\n  靠attention机制，不使用RNN和CNN，并行度高；\n  提出self-attention，自己和自己做attention，使得每个词都有全局的语义信息（长依赖）：由于Self-Attention是每个词和所有词都要计算Attention，所以不管他们中间有多长距离，最大的路径长度也都只是1，可以捕获长距离依赖关系；\n  提出multi-head attention，可以看成attention的ensemble版本，不同head学习不同的子空间语义；\n    参考资料\n Attention Is All You Need https://jalammar.github.io/illustrated-transformer/ https://zhuanlan.zhihu.com/p/39034683   ",
  "wordCount" : "96",
  "inLanguage": "en",
  "datePublished": "2018-11-12T00:00:00Z",
  "dateModified": "2021-03-20T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Shuryne"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://Shuryne.github.io/posts/%E4%BB%8Eseq2seq%E5%88%B0transformer/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Shuryne",
    "logo": {
      "@type": "ImageObject",
      "url": "https://Shuryne.github.io/favicon.ico"
    }
  }
}
</script>





</head>

<body class="" id="top">
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'G-B99LVDK48T', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>
<noscript>
    <style type="text/css">
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript>
<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://Shuryne.github.io" accesskey="h" title="Shuryne (Alt + H)">Shuryne</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                
                
            </span>
        </div>
        <ul id="menu" onscroll="menu_on_scroll()">
            <li>
                <a href="https://Shuryne.github.io/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://Shuryne.github.io/categories/" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
            <li>
                <a href="https://Shuryne.github.io/search/" title="Search">
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://Shuryne.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li></ul>
    </nav>
</header>

    <main class="main">

<article class="post-single">
  <header class="post-header">

    <h1 class="post-title">
      从seq2seq到Transformer
    </h1>
    <div class="post-meta">

November 12, 2018&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Shuryne

</div>
  </header> 

  <div class="post-content">
<p>关于Seq2Seq和Transformer</p>
<h4 id="1-sequence-to-sequence-learning-with-neural-networks">1. Sequence to Sequence Learning with Neural Networks<a hidden class="anchor" aria-hidden="true" href="#1-sequence-to-sequence-learning-with-neural-networks">#</a></h4>
<ul>
<li>
<p><code>encoder</code>以及<code>decoder</code>都采用<code>LSTM</code>模型</p>
</li>
<li>
<p>模型很简单，就是最普通的多层<code>LSTM</code></p>
</li>
<li>
<p>实现的不同之处：</p>
<ul>
<li>用两种不同的<code>LSTM</code>，一种处理输入序列，一种处理输出序列；以可忽略的计算成本增加参数数量，同时在多个语言对上训练<code>LSTM</code>；</li>
<li>更深的<code>LSTM</code>会比浅的效果更好，故论文模型选择了四层；</li>
<li>将输入的序列翻转之后作为输入效果提升；<!-- raw HTML omitted --></li>
</ul>
</li>
<li>
<p><code>decoder</code>应用了beam search来提升效果（每次生成词是取使得整个概率最高的前k个词作为候选）；beam size越大，效果越好，同时计算代价增大；</p>
</li>
<li>
<p>关于倒序输入效果提升：<code>rnn</code>是有偏模型，顺序越靠后的单词在最终占据的信息量越大，正序时最后一个词对应的state作为<code>decoder</code>的输入来预测第一个词，在<code>alignment</code>上来看显然这两个词并不是对齐的；倒序的话，<code>first word</code>成了<code>last word</code>，在<code>last state</code>中占据了主导，来预测<code>decoder</code>的第一个词，从某种意义上说实现了<code>alignment</code>，故效果提升；</p>
</li>
<li>
<p><code>decoder</code>本质上是一个<code>rnn</code>语言模型，不同的是在生成词的时候依赖于<code>encoder</code>的最后一个<code>hidden state</code>：</p>
</li>
<li>
<p>参考资料：</p>
<ul>
<li>Sequence to Sequence Learning with Neural Networks</li>
<li><a href="https://zhuanlan.zhihu.com/p/26985192">https://zhuanlan.zhihu.com/p/26985192</a></li>
</ul>
</li>
</ul>
<hr>
<h4 id="2-convolutional-sequence-to-sequence-learning">2. Convolutional Sequence to Sequence Learning<a hidden class="anchor" aria-hidden="true" href="#2-convolutional-sequence-to-sequence-learning">#</a></h4>
<ul>
<li>
<p>Seq2Seq 先把语句转换为一组词向量，通过对词向量的剪辑，提炼出语义向量。但对于如何剪辑有争议。有人提议使用<code>LSTM</code>等循环模型（RNN），来实现语义剪辑。RNN 模型的剪辑手段是：记忆门、遗忘门、和输出门。</p>
</li>
<li>
<p>RNN 模型的突出优势，是很好地解决了长距离依赖的难题；</p>
</li>
<li>
<p>作者使用<code>CNN</code>取代<code>RNN</code>循环模型，训练速度提高9倍，精度超越<code>RNN</code>；</p>
</li>
<li>
<p><strong>为什么更快？</strong></p>
<ul>
<li>卷积并行处理，而循环只能顺序处理，多个机器同时并行训练卷积模型，速度比串行训练循环模型快很多；</li>
<li>可用<code>GPU</code>芯片来加速卷积模型的训练，而暂时还没有硬件能够加速<code>RNN</code>的训练；</li>
</ul>
</li>
<li>
<p><strong>为什么更准？</strong></p>
<ul>
<li><code>CNN</code>的层层抽象，与<code>RNN</code>的三重门，其实异曲同工。虽手段不同，但目的都是忽略次要内容，传承重要内容。所以在精度方面二者差距不大；</li>
<li>但是层级结构与循环网络链结构相比，提供了一种较短的路径来捕获词之间远程的依赖关系，因此也可以更好地捕捉更复杂的关系；</li>
<li><code>Facebook translate</code> 与<code>Google translate</code>的精度差异，应该是由于<code>attention</code>的改进引起的；
<ul>
<li><code>Google Translate</code>的解码器使用单层<code>LSTM</code>模型，故<code>attention</code>也是单层的；<code>Facebook</code>的解码器使用<code>CNN</code>模型，是多层的，<code>attention</code> 是多跳的（multi-hop）；越是底层的<code>attention</code>越聚焦，细节越丰富；越是高层的<code>attention</code>，视野越开阔，抽象程度越高，越能抓住文章主旨；</li>
<li><code>Google Translate</code>使用的<code>attention</code>，依赖于编码器生成的语义向量，而不依赖于输入的原生态的词向量。而<code>Facebook</code>的<code>attention</code>，对语义向量和原生态词向量兼收并取；语义向量负责把握主旨，保证解码器的输出不偏题；原生态词向量关注措辞，保障解码器的输出用词得当；</li>
</ul>
</li>
</ul>
</li>
<li>
<p>将来<code>attention</code>的机制，还得融入规则。论文里只理解字面意思的<code>attention</code>的计算方式，无法理解“画外音”、“引经据典”、“含沙射影”的联想型语句。要正确理解“引经据典”和“含沙射影”，将来<code>attention</code>机制，还得融入知识图谱（张俊的猜想）；</p>
</li>
<li>
<p>模型结构：<code>encoder-decoder</code> +<code>attention</code>模块</p>
<ul>
<li>encoder 和 decoder采用了相同的卷积结构</li>
<li>非线性部分采用门控结构<code>GLM</code>；</li>
<li><code>attention</code>采用多跳注意<code>multi-hop attention</code>，即在<code>decoder</code>的每一个卷积层都会进行<code>attention</code>操作，并将结果输入到下一层；</li>
</ul>
</li>
<li>
<p>参考资料</p>
<ul>
<li>Convolutional Sequence to Sequence Learning</li>
<li><a href="https://zhuanlan.zhihu.com/p/26918935">https://zhuanlan.zhihu.com/p/26918935</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/27464080">https://zhuanlan.zhihu.com/p/27464080</a></li>
</ul>
</li>
</ul>
<hr>
<h4 id="3-attention-is-all-you-need">3. Attention Is All You Need<a hidden class="anchor" aria-hidden="true" href="#3-attention-is-all-you-need">#</a></h4>
<ul>
<li>
<p>优点：</p>
<ul>
<li>
<p>靠<code>attention</code>机制，不使用<code>RNN</code>和<code>CNN</code>，并行度高；</p>
</li>
<li>
<p>提出<code>self-attention</code>，自己和自己做<code>attention</code>，使得每个词都有全局的语义信息（长依赖）：由于<code>Self-Attention</code>是每个词和所有词都要计算<code>Attention</code>，所以不管他们中间有多长距离，最大的路径长度也都只是1，可以捕获长距离依赖关系；</p>
</li>
<li>
<p>提出<code>multi-head attention</code>，可以看成<code>attention</code>的<code>ensemble</code>版本，不同<code>head</code>学习不同的子空间语义；</p>
</li>
</ul>
</li>
<li>
<p>参考资料</p>
<ul>
<li>Attention Is All You Need</li>
<li><a href="https://jalammar.github.io/illustrated-transformer/">https://jalammar.github.io/illustrated-transformer/</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/39034683">https://zhuanlan.zhihu.com/p/39034683</a></li>
</ul>
</li>
</ul>
</div>
  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://Shuryne.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/">计算机</a></li>
      <li><a href="https://Shuryne.github.io/tags/nlp/">NLP</a></li>
      <li><a href="https://Shuryne.github.io/tags/transformer/">Transformer</a></li>
    </ul>
    <nav class="paginav">
      <a class="next" href="https://Shuryne.github.io/posts/%E6%B4%BB%E7%9D%80/">
        <span class="title">Next Page »</span>
        <br>
        <span>活着</span>
      </a>
    </nav>






<div class="share-buttons">
    <a target="_blank" rel="noopener noreferrer" aria-label="share 从seq2seq到Transformer on twitter"
        href="https://twitter.com/intent/tweet/?text=%e4%bb%8eseq2seq%e5%88%b0Transformer&amp;url=https%3a%2f%2fShuryne.github.io%2fposts%2f%25E4%25BB%258Eseq2seq%25E5%2588%25B0transformer%2f&amp;hashtags=%e8%ae%a1%e7%ae%97%e6%9c%ba%2cNLP%2cTransformer">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-253.927,424.544c135.939,0 210.268,-112.643 210.268,-210.268c0,-3.218 0,-6.437 -0.153,-9.502c14.406,-10.421 26.973,-23.448 36.935,-38.314c-13.18,5.824 -27.433,9.809 -42.452,11.648c15.326,-9.196 26.973,-23.602 32.49,-40.92c-14.252,8.429 -30.038,14.56 -46.896,17.931c-13.487,-14.406 -32.644,-23.295 -53.946,-23.295c-40.767,0 -73.87,33.104 -73.87,73.87c0,5.824 0.613,11.494 1.992,16.858c-61.456,-3.065 -115.862,-32.49 -152.337,-77.241c-6.284,10.881 -9.962,23.601 -9.962,37.088c0,25.594 13.027,48.276 32.95,61.456c-12.107,-0.307 -23.448,-3.678 -33.41,-9.196l0,0.92c0,35.862 25.441,65.594 59.311,72.49c-6.13,1.686 -12.72,2.606 -19.464,2.606c-4.751,0 -9.348,-0.46 -13.946,-1.38c9.349,29.426 36.628,50.728 68.965,51.341c-25.287,19.771 -57.164,31.571 -91.8,31.571c-5.977,0 -11.801,-0.306 -17.625,-1.073c32.337,21.15 71.264,33.41 112.95,33.41Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share 从seq2seq到Transformer on linkedin"
        href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fShuryne.github.io%2fposts%2f%25E4%25BB%258Eseq2seq%25E5%2588%25B0transformer%2f&amp;title=%e4%bb%8eseq2seq%e5%88%b0Transformer&amp;summary=%e4%bb%8eseq2seq%e5%88%b0Transformer&amp;source=https%3a%2f%2fShuryne.github.io%2fposts%2f%25E4%25BB%258Eseq2seq%25E5%2588%25B0transformer%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share 从seq2seq到Transformer on reddit"
        href="https://reddit.com/submit?url=https%3a%2f%2fShuryne.github.io%2fposts%2f%25E4%25BB%258Eseq2seq%25E5%2588%25B0transformer%2f&title=%e4%bb%8eseq2seq%e5%88%b0Transformer">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share 从seq2seq到Transformer on facebook"
        href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fShuryne.github.io%2fposts%2f%25E4%25BB%258Eseq2seq%25E5%2588%25B0transformer%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share 从seq2seq到Transformer on whatsapp"
        href="https://api.whatsapp.com/send?text=%e4%bb%8eseq2seq%e5%88%b0Transformer%20-%20https%3a%2f%2fShuryne.github.io%2fposts%2f%25E4%25BB%258Eseq2seq%25E5%2588%25B0transformer%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share 从seq2seq到Transformer on telegram"
        href="https://telegram.me/share/url?text=%e4%bb%8eseq2seq%e5%88%b0Transformer&amp;url=https%3a%2f%2fShuryne.github.io%2fposts%2f%25E4%25BB%258Eseq2seq%25E5%2588%25B0transformer%2f">
        <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28">
            <path
                d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
        </svg>
    </a>
</div>

  </footer>
</article>
    </main><footer class="footer">
    <span>&copy; 2021 <a href="https://Shuryne.github.io">Shuryne</a></span>
    <span>&middot;</span>
    <span>Powered by <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a></span>
    <span>&middot;</span>
    <span>Theme <a href="https://git.io/hugopapermod" rel="noopener" target="_blank">PaperMod</a></span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)">
    <button class="top-link" id="top-link" type="button" accesskey="g">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
            <path d="M12 6H0l6-6z" />
        </svg>
    </button>
</a>



<script defer src="/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js" integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5&#43;kdJvBz5iKbt6B5PJI="
    onload="hljs.initHighlightingOnLoad();"></script>
<script>
    window.onload = function () {
        if (localStorage.getItem("menu-scroll-position")) {
            document.getElementById('menu').scrollLeft = localStorage.getItem("menu-scroll-position");
        }
    }
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

    function menu_on_scroll() {
        localStorage.setItem("menu-scroll-position", document.getElementById('menu').scrollLeft);
    }

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>

</body>

</html>
