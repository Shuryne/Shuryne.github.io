---
ShowBreadCrumbs: false
TocOpen: false
author: Shuryne
categories:
- 孤独的程序员
date: 2021-06-26
description: ''
draft: true
isCJKLanguage: true
searchHidden: false
showToc: false
tags:
- CS笔记
title: 关键词抽取这件“小事”
weight: 100
---

> 关键词抽取，看似一件简单的小事，事实上目前的效果并不乐观

<!--more-->



### 一、常见算法及评价

#### 1. TF-IDF

说明：[TF-IDF][1]利用词频（内部频率信息）和逆文档频率（外部信息）综合对关键词进行权重计算：$Weight = Term Frequency（TF）*Inverse Document Frequency（IDF）$

时间复杂度：$O(n)$

评价：

1. 逆文档频率相当于利用外部统计信息对内部词频进行权重调整，实现了较强的`baseline`
2. 由于对外部信息有依赖，若外部信息不及时更新，会出现最近年份等数字词（2019等）的`IDF`值较高，从而导致总体权重较高；除此之外，很多数字词都会获得较高的权重，如23、500等，这可能是因为外部文档缺少日期之类的信息



#### 2. TextRank

说明：[TextRank][2]基于`PageRank`思想，考虑词的上下文共现（内部结构信息），构建关键词网络，并迭代计算节点边的权重

时间复杂度：

评价：

1. 图模型，速度上比`TF-IDF`低
2. 只利用了文档内部信息，缺少外部辅助信息，所以导致效果上会抽取出一些无关的高频词（通常是副词）
3. 后处理方面可以通过词性标注进一步过滤，但是严重依赖词性标注的性能，但是目前没看到有人这样做过



#### 3. Topic Model

说明：常用`Latent Dirichlet allocation（LDA）`模型

评价



####  4. Word2vec

说明：苏剑林在[利用Word2vec抽取关键词][3]中提出的一种基于`word2vec`的关键词抽取方法，核心思想是用文档中的词来生成原始文档（也即是一串连续词），不同的词生成文档的概率不同，概率较高的就是关键词

时间复杂度：$O(n^2)$

评价：

1. 对于长文本，效率下降极其厉害，若是篇章级别关键词抽取，不建议使用
2. 核心思想基于$p(s|w_i)=p(w_1,w_2,...,w_n|w_i)=\Sigma_{k=1}^{n}p(w_k|w_i)$，考虑了文档内部词之间的转移关系，没有考虑词之间顺序、窗口共现等结构关系，公式表达比较简单粗暴。只要一个词能够“复现”出全文，那就表示是关键词，理论上是有一定难度的



### 二、别人的经验

#### 1. 刘知远在[知乎中的回答]

* `TF-IDF`是一个很强的`baseline`，具有较强普适性，基本能应付大部分关键词抽取场景
* 主题模型抽取的关键词比较宽泛，不能很好体现主题
* `TextRank`并不比`TF-IDF`有明显优势，而且因为设计构建图和随机游走的迭代算法，效率较低
* 对中文来说，分词以及词性标注性能对关键词抽取效果至关重要
* 从性能上来说，监督方法比以上无监督方法都会好很多



**参考文献**

1. [TF-IDF Wiki][1]
2. [PageRank Wiki][4]

2. [TextRank Paper][2]

3. [科学空间][3]

4. [关键词抽取有哪些方案][5]



[1]: https://en.wikipedia.org/wiki/Tf–idf
[2]: https://www.aclweb.org/anthology/W04-3252.pdf "TextRank: Bringing Order into Text"
[3]: https://kexue.fm/archives/4316 "苏剑林-科学空间"
[4]: https://zh.wikipedia.org/wiki/PageRank
[5]: https://www.zhihu.com/question/21104071